{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df00f52d",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3 - Web APIs & NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2ef59",
   "metadata": {},
   "source": [
    "# 2_Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaabd9f",
   "metadata": {},
   "source": [
    "## Web Scraping from r/stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd195f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7209f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.pushshift.io/reddit/search/submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51937f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters to pull data from stocks subreddit \n",
    "# set 100 posts per pull as that's the max limit\n",
    "# apply date-time reference so that the same data can be pulled later in future running of this codebook\n",
    "params = {\n",
    "    \"subreddit\": \"stocks\",\n",
    "    \"size\": 100,\n",
    "    \"before\": 1626851005\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6351a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull data from website and check status code\n",
    "response = requests.get(url, params)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde63c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store data as an object \n",
    "# extract data key from dictionary\n",
    "# print length to check that the number of posts scraped == 100\n",
    "scraped_data = response.json()\n",
    "posts = scraped_data[\"data\"]\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206bfb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stocks</td>\n",
       "      <td>1626851004</td>\n",
       "      <td>Advise on Long Term Stock?</td>\n",
       "      <td>I am earning very little at the moment but I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stocks</td>\n",
       "      <td>1626847571</td>\n",
       "      <td>Earning plays</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stocks</td>\n",
       "      <td>1626847468</td>\n",
       "      <td>Going long vega? what is the maximum loss?</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stocks</td>\n",
       "      <td>1626847423</td>\n",
       "      <td>Dad told me to sell on Monday when the market ...</td>\n",
       "      <td>The stocks I chose were aapl, net, asts, icln,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stocks</td>\n",
       "      <td>1626847066</td>\n",
       "      <td>Newbie trader. Dad told me to sell when the ma...</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  created_utc                                              title  \\\n",
       "0    stocks   1626851004                         Advise on Long Term Stock?   \n",
       "1    stocks   1626847571                                      Earning plays   \n",
       "2    stocks   1626847468         Going long vega? what is the maximum loss?   \n",
       "3    stocks   1626847423  Dad told me to sell on Monday when the market ...   \n",
       "4    stocks   1626847066  Newbie trader. Dad told me to sell when the ma...   \n",
       "\n",
       "                                            selftext  \n",
       "0  I am earning very little at the moment but I w...  \n",
       "1                                          [removed]  \n",
       "2                                          [removed]  \n",
       "3  The stocks I chose were aapl, net, asts, icln,...  \n",
       "4                                          [removed]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe with key variables of interest needed for NLP \n",
    "df = pd.DataFrame(posts)\n",
    "data = df[[\"subreddit\", \"created_utc\", \"title\", \"selftext\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e2b0ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5100, 4)\n"
     ]
    }
   ],
   "source": [
    "# create loop to scrape data in a similar way for another 50 times \n",
    "row = 99 \n",
    "\n",
    "for i in range(50):\n",
    "    params = {\n",
    "        \"subreddit\": \"stocks\",\n",
    "        \"size\": 100,\n",
    "        \"before\": data.iloc[row, 1]\n",
    "    }\n",
    "    response = requests.get(url, params)\n",
    "    scraped_data = response.json()\n",
    "    posts = scraped_data[\"data\"]\n",
    "    df = pd.DataFrame(posts)\n",
    "    data_new = df[[\"subreddit\", \"created_utc\", \"title\", \"selftext\"]]\n",
    "    data = data.append(data_new, ignore_index=True)\n",
    "    row += 100\n",
    "    time.sleep(5)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2d976",
   "metadata": {},
   "source": [
    "## Prelim data cleaning to remove posts that are duplicates, removed and with no texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d221d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dataframe with posts that are neither removed nor blank (i.e. NaN value)\n",
    "stocks = data[(data[\"selftext\"].str.contains(r'\\[removed\\]') != True) \n",
    "              & (data[\"selftext\"].isna() == False) \n",
    "              & (data[\"selftext\"] != \"\")]\n",
    "stocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbfb5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-6d6a0c577d30>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stocks.drop_duplicates(subset=[\"selftext\"], keep='last', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1746, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicated posts within the subreddit and keep the last of the duplicates \n",
    "stocks.drop_duplicates(subset=[\"selftext\"], keep='last', inplace=True)\n",
    "stocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da016155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last post created:  2021-07-21 07:03:24\n",
      "first post created:  2021-06-22 20:17:38\n"
     ]
    }
   ],
   "source": [
    "# check the range of time during which the posts were created\n",
    "print(\"last post created: \", pd.to_datetime(stocks[\"created_utc\"][0], unit='s'))\n",
    "print(\"first post created: \", pd.to_datetime(stocks.iloc[-1,1], unit='s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "882a92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the post to 1700 so that the size of the dataset from both subreddits are equal \n",
    "stocks = stocks[0:1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16a41364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export dataframes to csv \n",
    "stocks.to_csv(\"../data/extracted/stocks_text.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a76646",
   "metadata": {},
   "source": [
    "## Web Scraping from r/CryptoCurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ea2bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters to pull data from CryptoCurrency subreddit \n",
    "# set 100 posts per pull as that's the max limit\n",
    "# apply date-time reference so that the same data can be pulled later in future running of this codebook\n",
    "params = {\n",
    "    \"subreddit\": \"CryptoCurrency\",\n",
    "    \"size\": 100,\n",
    "    \"before\": 1626851005\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3e6234b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull data from website and check status code\n",
    "response = requests.get(url, params)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b88e3f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store data as an object \n",
    "# extract data key from dictionary\n",
    "# print length to check that the number of posts scraped == 100\n",
    "scraped_data = response.json()\n",
    "posts = scraped_data[\"data\"]\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78d140c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>1626850949</td>\n",
       "      <td>Should I create a gymkhana with all my cryptoc...</td>\n",
       "      <td>Hello everyone, yesterday I was thinking about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>1626850702</td>\n",
       "      <td>A country’s ban on crypto is only valid if you...</td>\n",
       "      <td>So I don’t understand why countries can ban cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>1626850642</td>\n",
       "      <td>I was already convinced. Fibonacci golden rati...</td>\n",
       "      <td>Listen, nothing you read on the internet is fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>1626850580</td>\n",
       "      <td>*According to Research From Fidelity * - 71% o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>1626850543</td>\n",
       "      <td>Illegal Crypto Miners in Ukraine Found Manipul...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit  created_utc  \\\n",
       "0  CryptoCurrency   1626850949   \n",
       "1  CryptoCurrency   1626850702   \n",
       "2  CryptoCurrency   1626850642   \n",
       "3  CryptoCurrency   1626850580   \n",
       "4  CryptoCurrency   1626850543   \n",
       "\n",
       "                                               title  \\\n",
       "0  Should I create a gymkhana with all my cryptoc...   \n",
       "1  A country’s ban on crypto is only valid if you...   \n",
       "2  I was already convinced. Fibonacci golden rati...   \n",
       "3  *According to Research From Fidelity * - 71% o...   \n",
       "4  Illegal Crypto Miners in Ukraine Found Manipul...   \n",
       "\n",
       "                                            selftext  \n",
       "0  Hello everyone, yesterday I was thinking about...  \n",
       "1  So I don’t understand why countries can ban cr...  \n",
       "2  Listen, nothing you read on the internet is fi...  \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe with key variables of interest needed for NLP \n",
    "df = pd.DataFrame(posts)\n",
    "data = df[[\"subreddit\", \"created_utc\", \"title\", \"selftext\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bedfa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5100, 4)\n"
     ]
    }
   ],
   "source": [
    "# create loop to scrape data another 50 times \n",
    "row = 99\n",
    "for i in range(50):\n",
    "    params = {\n",
    "        \"subreddit\": \"CryptoCurrency\",\n",
    "        \"size\": 100,\n",
    "        \"before\": data.iloc[row, 1]\n",
    "    }\n",
    "    response = requests.get(url, params)\n",
    "    scraped_data = response.json()\n",
    "    posts = scraped_data[\"data\"]\n",
    "    df = pd.DataFrame(posts)\n",
    "    data_new = df[[\"subreddit\", \"created_utc\", \"title\", \"selftext\"]]\n",
    "    data = data.append(data_new, ignore_index=True)\n",
    "    row += 100\n",
    "    time.sleep(5)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1503e92",
   "metadata": {},
   "source": [
    "## Prelim data cleaning to remove posts that are duplicates, removed and with no texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e3f373f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2044, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dataframe with posts that are neither removed nor blank (i.e. NaN value)\n",
    "crypto = data[(data[\"selftext\"].str.contains(r'\\[removed\\]') != True) \n",
    "              & (data[\"selftext\"].isna() == False) \n",
    "              & (data[\"selftext\"] != \"\")]\n",
    "\n",
    "crypto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a2d2890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-0a624450e653>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  crypto.drop_duplicates(subset=[\"selftext\"], keep='last', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2006, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicated posts within the subreddit and keep the last of the duplicates \n",
    "crypto.drop_duplicates(subset=[\"selftext\"], keep='last', inplace=True)\n",
    "crypto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "375e32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the post to 1700 so that the size of the dataset from both subreddits are equal \n",
    "crypto = crypto[0:1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31c4e0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last post created:  2021-07-21 07:02:29\n",
      "first post created:  2021-07-18 15:17:13\n"
     ]
    }
   ],
   "source": [
    "# check the range of time during which the posts were created\n",
    "print(\"last post created: \", pd.to_datetime(crypto[\"created_utc\"][0], unit='s'))\n",
    "print(\"first post created: \", pd.to_datetime(crypto.iloc[-1,1], unit='s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ae6c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframes to csv \n",
    "crypto.to_csv(\"../data/extracted/crypto_text.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
