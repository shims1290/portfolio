{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2d48f1",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3 - Web APIs & NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d1cc4",
   "metadata": {},
   "source": [
    "# 01_Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c9ba7",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "\n",
    "Using `Logistic Regression` model and `Tf-idf Vectorization`, we developed an NLP model to optimise the contents within a subreddit community for relevance. The model obtained 95% accuracy score, meaning it can make 95 accurate prediction about the true membership of the post out of every 100 predictions. The recall/ sensitivity score of the model is also relatively high at 98%. This means that there is only a 2% chance that the model will misclassify posts that truly belongs to the subreddit as an irrelevant post. \n",
    "\n",
    "The model used to determine the relevance of the posts is trained and tested using 1,700 observations of past subreddit posts scraped across the r/stocks and r/CryptoCurrency subreddit communities in mid-2021. We primarily draw information and insights from the textual data within the respective subreddit post titles and contents for model training.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af53b7",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "Reddit Inc. is a successful social media company with increasing revenues potential. In October 2020, it averaged 52 million daily active users [(source)](\"https://www.wsj.com/articles/reddit-claims-52-million-daily-users-revealing-a-key-figure-for-social-media-platforms-11606822200\") and it expects to generate $170 million revenue in 2020, primarily from its ad business [(source)](\"https://www.businessofapps.com/data/reddit-statistics/\").\n",
    "\n",
    "Much of the success of the social media platform is owed to its ability to forge genuine and safe engagements among its users. With a mission to bring community and belonging to everyone in the world [(source)](\"https://www.redditinc.com/policies/transparency-report-2020\"), Reddit Inc. ensures the removal of spam posts or posts violating the content policy by admins, moderators and a scaled community moderation tool known as [AutoMod](\"https://www.reddit.com/wiki/automoderator/full-documentation\"). The chart below shows the nature and scale of content removal in 2020. \n",
    "\n",
    "<img src=\"https://www.redditinc.com/assets/images/site/Chart3b.png\" style=\"float: center; height: 300px\">\n",
    "\n",
    "<p style=\"text-align: center\">Chart Source: <a href=\"https://www.businessofapps.com/data/reddit-statistics/\">Reddit Inc.</a></p>\n",
    "\n",
    "With the growing popularity of the platform, more subreddits will likely emerge to cover various niche topics within a broader domain (e.g. data science vs data engineering). Moderators may find it challenging to curate posts to prevent content dilution as new reddit users may errorneously post contents under inappropriate subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d84b3",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "To help subreddit moderators ensure high content quality and relevance, we develop a classification tool using machine learning techniques (i.e. **Logistic Regression and Naive Bayes models**) to identify posts that are likely to be inappropriately posted under the \"wrong\" subreddits for removal. \n",
    "\n",
    "The success of the project depends on both the accuracy and sensitivity scores of the model:\n",
    "\n",
    "> 1) Accuracy score: This metric is useful as it tells us how many predictions were true. ***The higher the accuracy score, the better the model***.\n",
    "> \n",
    "> 2) Sensitivity score: This is also a key metric because we want to avoid labelling a post that is relevant to the subreddit as irrelevant. The removal of relevant posts will frustrate the subreddit members and discourage them from posting in the future. This runs counter to Reddit Inc.'s objective to improve user experience, grow user base and increase advertising revenue potential. As such, ***we want to minimise the false negatives as far as we can. A higher sensitivity score is better as it implies fewer false negatives***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eea59b",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "In the project pilot, we do so by capitalising on textual data scraped from the [r/Stocks](\"https://www.reddit.com/r/stocks/\") and [r/CryptoCurrency](\"https://www.reddit.com/r/CryptoCurrency/\") subreddits. These two subreddits are suitable for use as part of classification model development because both subreddits have:\n",
    "- **Large user base** (~3 millions each), implying strong advertising revenue potential. This also ensures availability and abundance of recent posts for sampling and model training.\n",
    "- **Text-rich posts** that are conducive for NLP analysis.\n",
    "\n",
    "The two datasets to be used for model training are as follows. Each dataset has **1,700** observations scraped from the respective subreddits. See `02 Data Extraction.ipynb` for detailed web scraping procedure and code. \n",
    ">* [`stocks.csv`](../data/extracted/stocks.csv)\n",
    ">* [`crypto.csv`](../data/extracted/crypto.csv)  \n",
    "\n",
    "The data dictionary of the extracted data is below:\n",
    "\n",
    "|Feature|Type|Description|\n",
    "|:---:|:---:|:---| \n",
    "|subreddit|*string*|Indicates the membership of the post, i.e. `stocks` for r/stocks and `CryptoCurrency` for r/CyptoCurrency.| \n",
    "|created_utc|*integer*|UTC or Coordinated Universal Time is the primary time standard by which the world regulates clocks and time. This indicates the time when the post was created. This is based on the Greenwich Mean Time or GMT is the clock time at the Royal Observatory in Greenwich, London. | \n",
    "|title|*string*|Title of the subreddit post.| \n",
    "|selftext|*string*|Contents of the subreddit post.| \n",
    "\n",
    "For model evaluation and analysis, we assume r/stocks to be the anchor subreddit that we want to optimise post curation and content relevance for. Posts from r/stocks will be labelled or tagged as true member to the r/stocks subreddit (or 1 if classification variable is dummified). By extension, posts from r/CryptoCurrency will be considered as non-member of the r/stocks subreddit (or 0 if dummified). \n",
    "\n",
    "The posts scraped are created between the following timeframe:\n",
    "* r/stocks: `2021-06-22 20:17:38` to `2021-07-21 07:03:24`\n",
    "* r/CryptoCurrency: `2021-07-18 15:17:13` to `2021-07-21 07:02:29`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d387990",
   "metadata": {},
   "source": [
    "# Directory\n",
    "\n",
    "02: Data Extraction  \n",
    "03: Data Cleaning, Exploratory Data Analysis & Vectorization  \n",
    "04: Modelling with CountVectorizer  \n",
    "05: Modelling with TF-IDF Vectorizer  \n",
    "06: Model Evaluation, Findings & Recommendations "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
